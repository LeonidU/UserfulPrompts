## Theory of LLM and Transformers

LLMs Will Always Hallucinate, and We Need to Live With This
https://arxiv.org/abs/2409.05746

Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?
https://arxiv.org/pdf/2405.05904

Alleviating Hallucinations of Large Language Models through Induced Hallucinations
https://arxiv.org/pdf/2312.15710

The Illusion of State in State-Space Models
https://arxiv.org/abs/2404.08819

Chain of Thought Empowers Transformers to Solve Inherently Serial Problems
https://arxiv.org/abs/2402.12875

How Can Deep Neural Networks Fail Even With Global Optima?
https://arxiv.org/pdf/2407.16872

Neural Exploratory Landscape Analysis
https://arxiv.org/pdf/2408.10672

Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models
https://arxiv.org/pdf/2408.08210

Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization
https://arxiv.org/pdf/2405.15071

Were RNNs All We Needed?
https://arxiv.org/pdf/2410.01201

Connectivity Structure and Dynamics of Nonlinear Recurrent Neural Networks
https://arxiv.org/pdf/2409.01969

Counterfactual Token Generation in Large Language Models
https://arxiv.org/pdf/2409.17027

Activation thresholds and expressiveness of polynomial neural networks
https://arxiv.org/pdf/2408.04569

TIGHT STABILITY, CONVERGENCE, AND ROBUSTNESS BOUNDS FOR PREDICTIVE CODING NETWORKS
https://arxiv.org/pdf/2410.04708

Can we teach language models to gloss endangered languages?
https://arxiv.org/pdf/2406.18895

Refusal in Language Models Is Mediated by a Single Direction
https://arxiv.org/pdf/2406.11717

SELF-DISCOVER: Large Language Models Self-Compose Reasoning Structures
https://arxiv.org/pdf/2402.03620

Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models
https://arxiv.org/pdf/2403.00794v1

Creativity Has Left the Chat: The Price of Debiasing Language Models
https://arxiv.org/pdf/2406.05587

Scientific Large Language Models: A Survey on Biological & Chemical Domains
https://arxiv.org/pdf/2405.12832

DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data
https://arxiv.org/pdf/2405.14333
https://huggingface.co/papers/2405.14333

You Need to Pay Better Attention: Rethinking the Mathematics of Attention Mechanism
https://arxiv.org/pdf/2403.01643

Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models
https://arxiv.org/pdf/2405.05417

Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory
https://arxiv.org/pdf/2311.08719

softmax is not enough (for sharp out-of-distribution)
https://arxiv.org/abs/2410.01104

Squared Earth Mover’s Distance-based Loss for Training Deep Neural Networks
https://arxiv.org/pdf/1611.05916

No “Zero-Shot” Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance
https://arxiv.org/pdf/2404.04125

Shortcut Learning in In-Context Learning: A Survey
https://arxiv.org/pdf/2411.02018

TL-PCA: Transfer Learning of Principal Component Analysis
https://arxiv.org/pdf/2410.10805

Shortcut Learning in In-Context Learning: A Survey
https://arxiv.org/pdf/2411.02018

DO I KNOW THIS ENTITY? KNOWLEDGE AWARENESS AND HALLUCINATIONS IN LANGUAGE MODELS
https://arxiv.org/pdf/2411.14257
